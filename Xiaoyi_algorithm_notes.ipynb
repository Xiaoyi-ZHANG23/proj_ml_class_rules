{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm is supposed to generate a list of rules based on PRISM algorithm discussed during the class, and should be able to work with both numerical and categorical data with no empty cells. This project is implemented based on Professor \tMarina Barsky's implementation plan and some code is borrowed from her. I also got direct help from her with regard to implementing the learn_one_rule algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation notes\n",
    "\n",
    "First, we need a datastructure to store each rule. The data structure is borrowed from Professor Marina Barsky\n",
    "\n",
    "\n",
    "Each Rule consists of antecedent (Left Hand Side) and consequent (Right Hand Side). The LHS includes multiple conditions joined with AND, and RHS is a class label. The Rule also needs to store its accuracy and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "        self.accuracy = 0\n",
    "        self.coverage = 0\n",
    "\n",
    "    def addCondition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def setParams(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "    \n",
    "    # Human-readable printing of this Rule\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of conditions contains several objects of class _Condition_. \n",
    "\n",
    "Each condition includes the _attribute name_ and the _value_. \n",
    "\n",
    "If the _value_ is numeric, then the condition also includes an additional field `true_false` which means the following: \n",
    "- *if true_false == True then values are >= value* \n",
    "- *if true_false == False then values are < value*\n",
    "- If *true_false is None*, then this condition is simply of form *categorical attribute = value*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            return \"{}>={}:{}\".format(self.attribute, self.value, self.true_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the `learn_one_rule` algorithm. The required parameters are the names of the columns, the current subset of data, and the class label (RHS of the rule we are trying to learn). The optional parameters are thresholds `min_coverage` and `min_accuracy`. For normal datasets we can set the coverage value to 30, for example, to prevent creating unreliable rules with insignificant support from data.\n",
    "\n",
    "The algorithm returns a new rule and maybe a subset of data covered by the Rule or the remaining data (not covered by the rule).    \n",
    "\n",
    "Please note that the algorithm I implemented is prioritizing accuracy, which means that for a 1.0 accuracy rule with 30 coverage, and a 0.9 accuracy rule with 30000 coverage, the first rule would be selected. \n",
    "\n",
    "The general idea of the implementation is that: \n",
    "1. Create a subset of the original data set that only contains the class label we are interested in \n",
    "2. Find all possible conditions, and for each condition, check if it is int(numerical) or not int(categorical data).\n",
    "3. If it is numerical data, get all possible values and sort the unique values from small to large. For all possible values, test the conditions as a. greater or equal to the value, or b, smaller than the value. Find the greater accuracy. The accuracy is compared with the current best accuracy and coverage.\n",
    "4. If it is categorical, iterate through all possible values to see what is the accuracy and coverage for each category.\n",
    "5. Check the current best result: \n",
    "- if I reach coverage 1, that means I can no longer improve and since every new condition would at least keep/reduce my covered subset, I don't want to continue. Thus, it is the best option. I add the current condition to my rule\n",
    "- else if I tested all possible conditions, I want to see if I reached a final accpetable result or not. If so, I return the rule with all conditions in it.\n",
    "- else if I reached a coverage smaller than min coverage, that means I can no longer subdivide, and have to stop. I check if it is good enough and if so I return the rule without current condition, as the current condition's coverage is too small.\n",
    "- else I have to continue, and I remove current attribute from the possible attribute list, and add the condition to the rule, and continue with the iterative loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def learn_one_rule(column, data, class_label, min_coverage=0, min_accuracy=0.6):\n",
    "    if len(data)==0:\n",
    "        return None\n",
    "    covered_subset = data.copy()\n",
    "    data2 = data.copy()\n",
    "    current_rule = Rule(class_label)\n",
    "    done = False\n",
    "    # filter out data with right labels\n",
    "    classheader = data2.columns[-1]\n",
    "    current_data = data2[data2[classheader] == class_label]\n",
    "    # make sure I am not operating the wrong set of data\n",
    "    columns = column.copy()\n",
    "    columns.pop()\n",
    "    \n",
    "    #get the best possible option\n",
    "    while not done:\n",
    "        #reset\n",
    "        current_accuracy = 0\n",
    "        current_coverage = 0\n",
    "        current_condition = Condition(None,None)\n",
    "        index = 0\n",
    "        #go through all possible attributes\n",
    "        for i in range(len(columns)):\n",
    "\n",
    "            current_attribute = columns[i]        \n",
    "        \n",
    "             #check if it is numerical, get unique values, for each value, there is two rules: greater or equal to, or less than\n",
    "            possible_values = current_data[current_attribute].unique().tolist()\n",
    "            if isinstance(possible_values[0], int) or isinstance(possible_values[0],float):\n",
    "                possible_values.sort()\n",
    "             #test every possible value for the current attribute\n",
    "            for value in possible_values:\n",
    "                #if dealing with numerical values\n",
    "                if isinstance(value, int) or isinstance(value,float):\n",
    "                    #get two sets of accuracy and coverage\n",
    "                    mycolumn1 = current_data[current_attribute]\n",
    "                    correct1 = mycolumn1[mycolumn1 >= value].count()\n",
    "                    mycolumn2 = data2[current_attribute]\n",
    "                    coverage1 = mycolumn2[mycolumn2 >= value].count()\n",
    "                    # this is to avoid 0/0 scenario\n",
    "                    if coverage1 == 0:\n",
    "                        accuracy1 = 0\n",
    "                    else:\n",
    "                        accuracy1 = correct1/coverage1\n",
    "                    mycolumn3 = current_data[current_attribute]\n",
    "                    correct = mycolumn3[mycolumn3 <value].count()\n",
    "                    column4 = data2[current_attribute]\n",
    "                    coverage = column4[column4 < value].count()\n",
    "                    if coverage == 0:\n",
    "                        accuracy = 0\n",
    "                    else:\n",
    "                        accuracy = correct/coverage\n",
    "                    #just here to avoid syntax problems, also set flag for later use\n",
    "                    GreaterThan = False\n",
    "                    # get the best among the two\n",
    "                    if accuracy1 > accuracy:\n",
    "                        GreaterThan = True\n",
    "                        accuracy = accuracy1\n",
    "                        coverage = coverage1\n",
    "                    elif accuracy1 == accuracy:\n",
    "                        if coverage1 > coverage: \n",
    "                            GreaterThan = True\n",
    "                            coverage = coverage1\n",
    "                    Int = True\n",
    "                    # if the result is good enough to be recorded, record as condition, and update the \n",
    "                    # accuracy/coverage/covered set\n",
    "                    if coverage >= min_coverage:\n",
    "                        if accuracy > current_accuracy:\n",
    "                            index = i\n",
    "                            current_coverage = coverage\n",
    "                            current_accuracy = accuracy\n",
    "                            current_condition= Condition(current_attribute, value, GreaterThan) \n",
    "                            if GreaterThan: \n",
    "                                covered_subset = data2[data2[current_attribute] >= value] \n",
    "                            else:\n",
    "                                covered_subset = data2[data2[current_attribute] < value] \n",
    "                        # if accuracy is the same, compare coverage\n",
    "                        elif accuracy == current_accuracy and coverage > current_coverage:\n",
    "                            index = i\n",
    "                            current_coverage = coverage\n",
    "                            current_accuracy = accuracy\n",
    "                            current_condition= Condition(current_attribute, value,GreaterThan) \n",
    "                            if GreaterThan: \n",
    "                                covered_subset = data2[data2[current_attribute] >= value] \n",
    "                            else:\n",
    "                                covered_subset = data2[data2[current_attribute] < value]\n",
    "                else:\n",
    "                #compute accuracy\n",
    "                    correct = current_data[current_attribute].value_counts()[value]\n",
    "                    coverage = data2[current_attribute].value_counts()[value]\n",
    "                    accuracy = correct/coverage\n",
    "                    #choose the best option based on accuracy\n",
    "                    if coverage >= min_coverage:\n",
    "                        if accuracy > current_accuracy:\n",
    "                            current_coverage = coverage\n",
    "                            current_accuracy = accuracy\n",
    "                            current_condition= Condition(current_attribute, value) \n",
    "                            covered_subset = data2[data2[current_attribute] == value] \n",
    "                            index = i\n",
    "                        # if accuracy is the same, compare coverage\n",
    "                        elif accuracy == current_accuracy and coverage > current_coverage:\n",
    "                            current_coverage = coverage\n",
    "                            current_accuracy = accuracy\n",
    "                            current_condition= Condition(current_attribute, value) \n",
    "                            covered_subset = data2[data2[current_attribute] == value] \n",
    "                            index = i\n",
    "        #if reached to the end accuracy = 1.0, add to rule and terminate\n",
    "        if current_accuracy == 1.0 and current_coverage > min_coverage:\n",
    "            done = True\n",
    "            current_rule.addCondition(current_condition)\n",
    "            current_rule.accuracy = current_accuracy\n",
    "            current_rule.coverage = current_coverage\n",
    "        #if reached to the end that is acceptable, add to rule and terminate\n",
    "        elif len(columns) == 0: \n",
    "            done = True  \n",
    "            if current_rule.accuracy <= min_accuracy or current_rule.coverage < min_coverage:\n",
    "                return (None, None)\n",
    "\n",
    "        #if no rule possible, return none, else, we reached an end and is done\n",
    "        elif current_coverage < min_coverage:\n",
    "\n",
    "            if current_rule.accuracy <= min_accuracy or current_rule.coverage < min_coverage:\n",
    "                return (None, None)\n",
    "            done = True                \n",
    "        #default: not done yet, continue\n",
    "        else: \n",
    "            #update possible attributes\n",
    "            columns.pop(index)\n",
    "            current_rule.addCondition(current_condition)\n",
    "            data2 = covered_subset    \n",
    "            current_data = data2[data2[classheader] == class_label]\n",
    "            current_rule.accuracy = current_accuracy\n",
    "            current_rule.coverage = current_coverage\n",
    "            #reset\n",
    "    return (current_rule, covered_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the main algorithm `learn_rules` takes as parameters list of columns, with the last column representing the class label, and the original data in form of pandas dataframe. Two optional threshold parameters `min_coverage` and `min_accuracy` set up the conditions of rule's validity for a given dataset.\n",
    "\n",
    "In order to cover the PRISM algorithm, I also added a small part that would run the learn_one_rule algorithm repeatedly to generate the best possible result. Unfortunately, that means the time is at least doubled and I am unable to improve on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def learn_rules (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. \n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn one rule \n",
    "            rule, subset = learn_one_rule(columns, current_data, class_label, min_coverage, min_accuracy)\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "            copylabel = class_labels.copy()\n",
    "            copylabel.remove(class_label)\n",
    "            for mylabel in copylabel:\n",
    "                myrule, mysubset = learn_one_rule(columns, current_data, mylabel, min_coverage, min_accuracy)\n",
    "                if myrule is not None and (myrule.accuracy > rule.accuracy or myrule.coverage > rule.coverage):\n",
    "                    rule, subset = myrule, mysubset\n",
    "            # If we get the rule with accuracy and coverage above threshold\n",
    "            \n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "                #try get the best result.\n",
    "                for id in subset.index:\n",
    "                    current_data.drop(index = id, inplace = True)\n",
    "                    current_data = current_data.dropna()\n",
    "                   \n",
    "            else:\n",
    "                done = True \n",
    "\n",
    "                    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correctness test  (Borrowed from Professor Marina Barsky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your algorithm on the original dataset from the PRISM paper.\n",
    "\n",
    "The dataset was downloaded from [here](https://archive.ics.uci.edu/ml/datasets/Lenses). The CSV version is included in this repository.\n",
    "\n",
    "**Attribute Information**:\n",
    "\n",
    "3 Classes:\n",
    "- __1__ : the patient should be fitted with __hard__ contact lenses,\n",
    "- __2__ : the patient should be fitted with __soft__ contact lenses,\n",
    "- __3__ : the patient should __not__ be fitted with contact lenses.\n",
    "\n",
    "\n",
    "Attributes:\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Presbyopia is physiological insufficiency of accommodation associated with the aging of the eye that results in progressively worsening ability to focus clearly on close objects. So \"age=presbiopic\" means old.\n",
    "\n",
    "Hypermetropia: far-sightedness, also known as long-sightedness - cannot see close.\n",
    "Myopia: nearsightedness - cannot see at distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'spectacles', 'astigmatism', 'tear production rate',\n",
       "       'lenses type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_file = \"contact_lenses.csv\"\n",
    "data = pd.read_csv(data_file, index_col=['id'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace numbers with actual values - for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age   spectacles astigmatism tear production rate lenses type\n",
      "id                                                                  \n",
      "1    young  nearsighted          no              reduced        none\n",
      "2    young  nearsighted          no               normal        soft\n",
      "3    young  nearsighted         yes              reduced        none\n",
      "4    young  nearsighted         yes               normal        hard\n",
      "5    young   farsighted          no              reduced        none\n",
      "6    young   farsighted          no               normal        soft\n",
      "7    young   farsighted         yes              reduced        none\n",
      "8    young   farsighted         yes               normal        hard\n",
      "9   medium  nearsighted          no              reduced        none\n",
      "10  medium  nearsighted          no               normal        soft\n",
      "11  medium  nearsighted         yes              reduced        none\n",
      "12  medium  nearsighted         yes               normal        hard\n",
      "13  medium   farsighted          no              reduced        none\n",
      "14  medium   farsighted          no               normal        soft\n",
      "15  medium   farsighted         yes              reduced        none\n",
      "16  medium   farsighted         yes               normal        none\n",
      "17     old  nearsighted          no              reduced        none\n",
      "18     old  nearsighted          no               normal        none\n",
      "19     old  nearsighted         yes              reduced        none\n",
      "20     old  nearsighted         yes               normal        hard\n",
      "21     old   farsighted          no              reduced        none\n",
      "22     old   farsighted          no               normal        soft\n",
      "23     old   farsighted         yes              reduced        none\n",
      "24     old   farsighted         yes               normal        none\n"
     ]
    }
   ],
   "source": [
    "# classes\n",
    "conditions = [ data['lenses type'].eq(1), data['lenses type'].eq(2), data['lenses type'].eq(3)]\n",
    "choices = [\"hard\",\"soft\",\"none\"]\n",
    "\n",
    "data['lenses type'] = np.select(conditions, choices)\n",
    "\n",
    "# age groups\n",
    "conditions = [ data['age'].eq(1), data['age'].eq(2), data['age'].eq(3)]\n",
    "choices = [\"young\",\"medium\",\"old\"]\n",
    "\n",
    "data['age'] = np.select(conditions, choices)\n",
    "\n",
    "# spectacles\n",
    "conditions = [ data['spectacles'].eq(1), data['spectacles'].eq(2)]\n",
    "choices = [\"nearsighted\",\"farsighted\"]\n",
    "\n",
    "data['spectacles'] = np.select(conditions, choices)\n",
    "\n",
    "# astigmatism\n",
    "conditions = [ data['astigmatism'].eq(1), data['astigmatism'].eq(2)]\n",
    "choices = [\"no\",\"yes\"]\n",
    "\n",
    "data['astigmatism'] = np.select(conditions, choices)\n",
    "\n",
    "# tear production rate\n",
    "conditions = [ data['tear production rate'].eq(1), data['tear production rate'].eq(2)]\n",
    "choices = [\"reduced\",\"normal\"]\n",
    "\n",
    "data['tear production rate'] = np.select(conditions, choices)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test (do not run it before you finished the implementation of the rule learning algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
      "If [astigmatism=no, spectacles=farsighted] then soft. Coverage:3, accuracy: 1.0\n",
      "If [astigmatism=yes, spectacles=nearsighted] then hard. Coverage:3, accuracy: 1.0\n",
      "If [age=old] then none. Coverage:2, accuracy: 1.0\n",
      "If [spectacles=nearsighted] then soft. Coverage:2, accuracy: 1.0\n",
      "If [age=medium, spectacles=farsighted, astigmatism=yes, tear production rate=normal] then none. Coverage:1, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_list = data.columns.to_numpy().tolist()\n",
    "\n",
    "rules = learn_rules (column_list, data, None, 1, 0.95)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manual evaluationi the method seems to work with a better result from professor's method, meaning that it is more accuracy in terms of the PRISM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marina Barsky's results are given below for comparison:\n",
    "\n",
    "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, spectacles=farsighted] then soft. Coverage:3, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, age=young] then soft. Coverage:1, accuracy: 1.0\n",
    "\n",
    "If [astigmatism=no, age=medium] then soft. Coverage:1, accuracy: 1.0\n",
    "\n",
    "If [age=young] then hard. Coverage:2, accuracy: 1.0\n",
    "\n",
    "If [spectacles=nearsighted, astigmatism=yes] then hard. Coverage:2, accuracy: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
